input {
   relp {
      port	 => "${RELPTLSPORT}"
      codec	 => "json"
      ssl_enable => true
      ssl_cert	 => "${SERVERCRT}"
      ssl_key	 => "${SERVERKEY}"
      ssl_cacert => "<your_CA_key_here>"
      ssl_verify => false
   }
}

filter {

# This if statement can be edited as needed, this filter followed others, and we added haproxy as a program field in the JSON message.
if "processed" not in [tags] and [program] == "haproxy" {
    grok {
        match => { "message" => '^<%{NONNEGINT:priority}>%{SYSLOGTIMESTAMP} %{DATA:syslog_process}: %{SYSLOGHOST:haproxy_hostname} %{IP:client_ip}:%{INT:client_port} \[%{HAPROXYDATE:accept_date}\] %{NOTSPACE:frontend_name} %{NOTSPACE:backend_name}/%{NOTSPACE:server_name} %{INT:time_request}/%{INT:time_queue}/%{INT:time_backend_connect}/%{INT:time_backend_response}/%{NOTSPACE:time_duration} %{INT:http_status_code} %{NOTSPACE:bytes_read} %{DATA:captured_request_cookie} %{DATA:captured_response_cookie} %{NOTSPACE:termination_state} %{INT:actconn}/%{INT:feconn}/%{INT:beconn}/%{INT:srvconn}/%{NOTSPACE:retries} %{INT:srv_queue}/%{INT:backend_queue} (\{%{HAPROXYCAPTUREDREQUESTHEADERS}\})?( )?(\{%{HAPROXYCAPTUREDRESPONSEHEADERS}\})?( )?"(<BADREQ>|(%{WORD:http_verb} (%{URIPROTO:http_proto}://)?(?:%{USER:http_user}(?::[^@]*)?@)?(?:%{URIHOST:http_host})?(?:%{NOTSPACE:http_request})?( HTTP/%{NUMBER:http_version})?))?"' }

        add_field => { "splunksourcetype" => "haproxy" }
        add_field => { "splunksource" => "%{backend_name}" }
        add_tag => [ "haproxy_log", "processed" ]
    }

# Had this to still process the message, but then you can direct it where desired.
    if "_grokparsefailure" in [tags] {
	mutate {
	    add_field => { "splunksourcetype" => "haproxy_other" }
            add_field => { "splunksource" => "%{severity_label}" }
            add_tag => [ "haproxy_log", "processed" ]
        }
    }

    if "haproxy_log" in [tags] {

# This line is significant, it sets up the event message in the format Splunk liked. I could not find another way to insert newlines, so this worked and I kept it.
	mutate {
	    add_field => { "splunkmessage" => "!!NL%{message}!!NLEC2_Name=%{Name}!!NLEnvironment=%{Environment}!!NLEC2_Role=%{SrvRole}!!NLOS=%{OS}!!NLhost=%{haproxy_hostname}!!NLseverity=%{severity}!!NLOSType=%{OSFamily}!!NLpriority=%{priority}!!NLprogram=%{program}!!NLfacility_label=%{facility_label}!!NLlogsource=%{logsource}!!NLfacility=%{facility}!!NLEC2_AZ=%{AZ}!!NLEC2_VPC=%{VPC ID}!!NLEC2_Subnet=%{Subnet ID}!!NLRelayIP=%{relayip}!!NLseverity_label=%{severity_label}!!NLEC2_Group=%{Group}!!NLEC2_InstanceID=%{InstanceID}!!NLRelayHost=%{relayhost}" }
	    copy => { "haproxy_hostname" => "hostname" }
        }

        mutate { convert => { "splunkmessage" => "string" } }

# Replace the '!!NL" with an actual newline (represented by actual newline in the gsub)
	mutate { gsub => [ "splunkmessage", "!!NL", "
"]
	}

	date {
	    timezone => "America/New_York"
	    match => [ "accept_date", "dd/MMM/yyyy:HH:mm:ss.SSS" ]
	}

# Splunk needs the event sent to it with epochtime. This line converts the timestamp to epochtime.
	ruby { code => "event.set('epochtime', (1000000*event.get('@timestamp').to_f).round(0))" }
    }

}

}

output {

# Should be self explanatory, but most of these fields are pulled out as environment variables for the service. See the README for details.
if "haproxy_log" in [tags] {
   http {
      format => "json"
      content_type => "application/json"
      http_method => "post"
      url => "https://http-inputs-natss.splunkcloud.com/services/collector"

      headers => ["Authorization", "Splunk ${SPLUNKAUTH}"]

      mapping => {
        "index"         => "${LINUXWEBLOGSPLUNKIDX}"
        "time"          => "%{epochtime}"
        "host"          => "%{hostname}"
        "source"        => "%{splunksource}"
        "sourcetype"    => "%{splunksourcetype}"
        "event"         => "%{hostname} %{tag} %{splunkmessage}"
      }

   }
}

}

output {

if "haproxy_log" in [tags] {
    s3 {
        id => "<desired ID>"

        bucket => "${S3BUCKET}"
        prefix => "haproxy-logs/%{+YYYY}/%{+MM}/%{+dd}/%{+HH}/%{hostname}/%{splunksourcetype}"

        size_file => 10485760
        time_file => 60
        # storage_class => "STANDARD, REDUCED_REDUNDANCY, STANDARD_IA"
        encoding => "gzip"
        codec => "json_lines"
        canned_acl => "private"
        temporary_directory => "/data/logstash/relplinuxsyslogs_s3"
    }
}

}